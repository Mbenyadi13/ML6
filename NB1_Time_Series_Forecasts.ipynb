{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2dd3c2c",
   "metadata": {},
   "source": [
    "# Part 1: Time Series Analysis (1 day)📈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb876e11",
   "metadata": {},
   "source": [
    "What is a time serie ? Simply put, it's a dataset where each value is measured at a known given time. Whether it's stock prices, temperature measurements, sales figures, or any other sequential data, time series data holds a rich tapestry of information about how phenomena evolve over time. Typically with time series, we want to estimate the evolution of a phenomenom with time i.e. make predictions for the future. Thus, the temporal order of the dataset is of paramount significance!\n",
    "\n",
    "Unlike cross-sectional data, where observations are independent of each other, the temporal arrangement in time series carries inherent dependencies. Patterns, trends, and seasonal variations often emerge, providing invaluable insights into the behavior of the underlying process.\n",
    "\n",
    "In this notebook, we will manipulate a simple time series dataset with Pandas to explore the following concepts:\n",
    "- Patterns (Trend, Seasonality, Noise) and Additive / Multiplicative decomposition\n",
    "- Stationarity & Heteroskedasticity (Differencing & Log transform)\n",
    "- Autocorrelation (ACF, PACF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399da4c9",
   "metadata": {},
   "source": [
    "**Objectives**\n",
    "- Get to know the theory behind time series\n",
    "- Analyse time series datasets with Pandas\n",
    "- Discover main time series analysis challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8308a9b2",
   "metadata": {},
   "source": [
    "**Resources**\n",
    "\n",
    "- https://www.youtube.com/watch?v=FsroWpkUuYI&list=PLjwX9KFWtvNnOc4HtsvaDf1XYG3O5bv5s\n",
    "- https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "- https://jakevdp.github.io/PythonDataScienceHandbook/03.11-working-with-time-series.html\n",
    "- https://www.kaggle.com/code/prashant111/complete-guide-on-time-series-analysis-in-python\n",
    "- https://perso.math.univ-toulouse.fr/jydauxoi/files/2017/04/poly_eleves.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf6352d",
   "metadata": {},
   "source": [
    "**Required librairies**\n",
    "- [ ] numpy\n",
    "- [ ] pandas\n",
    "- [ ] matplotlib\n",
    "- [ ] seaborn\n",
    "- [ ] pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bb9e67",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import required packages\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ML6/lib/python3.12/site-packages/pandas/__init__.py:37\u001b[39m\n\u001b[32m     30\u001b[39m     _module = _err.name\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     32\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC extension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not built. If you want to import \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     33\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpandas from the source directory, you may need to run \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     34\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mpython setup.py build_ext\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to build the C extensions first.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_err\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     38\u001b[39m     get_option,\n\u001b[32m     39\u001b[39m     set_option,\n\u001b[32m     40\u001b[39m     reset_option,\n\u001b[32m     41\u001b[39m     describe_option,\n\u001b[32m     42\u001b[39m     option_context,\n\u001b[32m     43\u001b[39m     options,\n\u001b[32m     44\u001b[39m )\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ML6/lib/python3.12/site-packages/pandas/_config/__init__.py:20\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mpandas._config is considered explicitly upstream of everything else in pandas,\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mshould have no intra-pandas dependencies.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m \u001b[33;03mare initialized.\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      8\u001b[39m __all__ = [\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdetect_console_encoding\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mwarn_copy_on_write\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dates  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     23\u001b[39m     _global_config,\n\u001b[32m     24\u001b[39m     describe_option,\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m     set_option,\n\u001b[32m     30\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ML6/lib/python3.12/site-packages/pandas/_config/config.py:68\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     59\u001b[39m     TYPE_CHECKING,\n\u001b[32m     60\u001b[39m     Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     cast,\n\u001b[32m     65\u001b[39m )\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_typing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     69\u001b[39m     F,\n\u001b[32m     70\u001b[39m     T,\n\u001b[32m     71\u001b[39m )\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_exceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ML6/lib/python3.12/site-packages/pandas/_typing.py:198\u001b[39m\n\u001b[32m    192\u001b[39m Frequency = Union[\u001b[38;5;28mstr\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBaseOffset\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    193\u001b[39m Axes = ListLike\n\u001b[32m    195\u001b[39m RandomState = Union[\n\u001b[32m    196\u001b[39m     \u001b[38;5;28mint\u001b[39m,\n\u001b[32m    197\u001b[39m     np.ndarray,\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m.Generator,\n\u001b[32m    199\u001b[39m     np.random.BitGenerator,\n\u001b[32m    200\u001b[39m     np.random.RandomState,\n\u001b[32m    201\u001b[39m ]\n\u001b[32m    203\u001b[39m \u001b[38;5;66;03m# dtypes\u001b[39;00m\n\u001b[32m    204\u001b[39m NpDtype = Union[\u001b[38;5;28mstr\u001b[39m, np.dtype, type_t[Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mobject\u001b[39m]]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ML6/lib/python3.12/site-packages/numpy/__init__.py:721\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ML6/lib/python3.12/site-packages/numpy/random/__init__.py:180\u001b[39m\n\u001b[32m    126\u001b[39m __all__ = [\n\u001b[32m    127\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbeta\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    128\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbinomial\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    176\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mzipf\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    177\u001b[39m ]\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# add these for module-freeze analysis (like PyInstaller)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pickle\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _common\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _bounded_integers\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/ML6/lib/python3.12/site-packages/numpy/random/_pickle.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmtrand\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomState\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_philox\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Philox\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pcg64\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PCG64, PCG64DXSM\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy/random/mtrand.pyx:1\u001b[39m, in \u001b[36minit numpy.random.mtrand\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pmdarima as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7324fe",
   "metadata": {},
   "source": [
    "# 1. Manipulate time series with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67526acb",
   "metadata": {},
   "source": [
    "### 1.1 Load & visualize the Air Passengers dataset ✈️ 💺"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff994ff",
   "metadata": {},
   "source": [
    "Learn how to manipulate a Pandas series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfa944f",
   "metadata": {},
   "source": [
    "**Resources**\n",
    "- https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "- https://jakevdp.github.io/PythonDataScienceHandbook/03.11-working-with-time-series.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf254b0",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "- Load and visualize the dataset\n",
    "- What can you tell about the overall trend of the data ?\n",
    "- Select and plot a specific year (e.g. 1952) from the data using the `.index.year` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f8c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.datasets import load_airpassengers\n",
    "\n",
    "# Load dataset\n",
    "START_DATE = '1949-01-01'\n",
    "airline = load_airpassengers(as_series=True)\n",
    "\n",
    "# There's no DateTimeIndex from the bundled dataset. So let's add one.\n",
    "airline.index = pd.date_range(START_DATE, periods=len(airline), freq='MS')\n",
    "\n",
    "# Write definitions to visualize, describe and eventually clean data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52059b08",
   "metadata": {},
   "source": [
    "### 1.2 Change the sampling (D/M/Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f3c2c",
   "metadata": {},
   "source": [
    "Different months have different numbers of days. Calculating the number of passengers per day might help remove this uninteresting variation from the series!\n",
    "\n",
    "**TODO**\n",
    "- Create a new time serie representing the daily number of passengers using the `.index.days_in_month` attribute\n",
    "- Visualize the old and new serie: do you observe any difference ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45307a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of airline passengers per day instead of months\n",
    "\n",
    "\n",
    "# Plot the unadjusted and adjusted series\n",
    "fig, axes = plt.subplots(2, 1, sharex=True, figsize=(12, 8))\n",
    "\n",
    "axes[0].plot(airline)\n",
    "axes[0].set(ylabel='Passengers (thousands)')\n",
    "\n",
    "axes[1].plot(airline_adj)\n",
    "axes[1].set(xlabel='Month', ylabel='Passengers per day (thousands)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5536177",
   "metadata": {},
   "source": [
    "### 1.3 Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfcdd78",
   "metadata": {},
   "source": [
    "Interpolation is useful when there are missing values which we don't want to discard completely. As such, it can be used instead of the now well-known `dropna()` method.\n",
    "\n",
    "Another use case for interpolation is when resampling a time series. The airline passengers data is given with 1 month intervals. What if we want to know (and predict) the airline frequentation at smaller intervals ? For this we can use the `resample()` and `interpolate` methods!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7764b23c",
   "metadata": {},
   "source": [
    "**Resources**\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html\n",
    "- https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.interpolate.html <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e004a6",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "- Select a single year from the dataset and resample it to daily time\n",
    "- Call `resample()` to resample the series to daily intervals\n",
    "- Call `interpolate()` and play with the different methods\n",
    "- Plot the results to show the differences  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6173a6",
   "metadata": {},
   "source": [
    "# 2. Identifying patterns: Trend & Seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e058c1",
   "metadata": {},
   "source": [
    "**Theory**\n",
    "\n",
    "To analyze, and eventually forecast, a time series, it is useful to break it down into simple components. Typically, a time series is modeled as the contribution of three components:\n",
    "- The Trend $T$: long-term movement or direction of the time series, related to the underlying growth or decline such as in upward, downward or flat trend\n",
    "- The Seasonality $S$: repeating patterns or fluctuations that occur in a time series at regular intervals, such as daily, weekly, monthly, or yearly patterns\n",
    "- The Residuals $R$: residual random variations or noise that cannot be explained by the trend and seasonality\n",
    "\n",
    "Decomposing the signal into these components is useful for\n",
    "- Removing noise arising from measurement errors or random fluctuations\n",
    "- Isolate trend and seasonality to model and analyze them separately\n",
    "- Make better forecasts\n",
    "\n",
    "There are two main types of seasonal decomposition: the **additive** and **multiplicative** decomposition.\n",
    "The additive model tries to find the best possible components $T_t$, $S_t$, $R_t$ such that at all times $t$ the serie $Y_t$ is decomposed as\n",
    "$$ Y_t = T_t + S_t + R_t$$  \n",
    "The additive model is linear since the variations of the trend and seasonality are independent of each other. When the seasonal (periodic) variations in the time serie seem to be independent of the trend, additive models are preferred. \n",
    "\n",
    "Conversely, the multiplicative model tries to find the best possible components $T_t$, $S_t$, $R_t$ such that at all times $t$ the serie $Y_t$ is decomposed as\n",
    "$$ Y_t = T_t * S_t * R_t$$\n",
    "Note that the multiplicative model can be seen as an additive model in log-space, i.e. it is completely equivalent to\n",
    "$$ \\log Y_t = \\log T_t + \\log S_t + \\log R_t$$\n",
    "Multiplicatrive models are non linear since the variations in the trend imply variations in seasonality, and vice-versa. When the seasonal variations in the time series seems to change with time, multiplicative models are preferred.\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a374a0d",
   "metadata": {},
   "source": [
    "**Resources**\n",
    "\n",
    "- https://medium.com/analytics-vidhya/time-series-decomposition-part-i-trend-cycle-computation-29fac227896a\n",
    "- https://otexts.com/fpp2/components.html\n",
    "- https://machinelearningmastery.com/decompose-time-series-data-trend-seasonality/\n",
    "- https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html<br/>\n",
    "- https://towardsdatascience.com/time-series-analysis-resampling-shifting-and-rolling-f5664ddef77e\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b76b6c",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "\n",
    "Back to the monthly dataset (do not continue with the interpolated one).\n",
    "- Use the function `seasonal_decompose()` from Statmodels to decompose the dataset into its components with both an additive and multiplicative model.\n",
    "- Visualize the results. Which model works best ?\n",
    "- Perform your own decomposition using the `rolling()` method from Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e58b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_average(data):\n",
    "    avg = data.groupby(data.index.month).mean()\n",
    "    index = pd.date_range(START_DATE, periods=len(airline), freq='MS')\n",
    "    \n",
    "    data = np.zeros(len(index))\n",
    "    \n",
    "    for i,n in enumerate(index):\n",
    "        data[i] = avg[n.month]\n",
    "\n",
    "    new_data = pd.Series(data=data, index=index)\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "\n",
    "def custom_seasonal(data, model='additive'):\n",
    "    \n",
    "    # Compute the trend = rolling mean\n",
    "\n",
    "\n",
    "    if model == 'additive':\n",
    "        \n",
    "        # Subtract the trend to get the seasonal + noise component\n",
    "\n",
    "\n",
    "        # Take the average over each month to get the pure seasonal component\n",
    "\n",
    "\n",
    "        # The residual is the difference between the data and trend + seasonal\n",
    "\n",
    "        \n",
    "    elif model == 'multiplicative':\n",
    "        \n",
    "        # Divice by the trend to get the seasonal * noise component\n",
    "\n",
    "\n",
    "        # Take the average over each month to get the pure seasonal component\n",
    "\n",
    "\n",
    "        # The residual is the division between the data and trend * seasonal\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        raise ValueError('Unknown model name')\n",
    "    \n",
    "    # Plot results\n",
    "    fig, axes = plt.subplots(4, 1, sharex=True, figsize=(12, 8))\n",
    "    \n",
    "    axes[0].plot(data)\n",
    "    axes[1].plot(trend)\n",
    "    axes[2].plot(seasonal)\n",
    "    axes[3].plot(residual)\n",
    "\n",
    "custom_seasonal(airline_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93747784",
   "metadata": {},
   "source": [
    "# 3. Stationarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0d520e",
   "metadata": {},
   "source": [
    "### 3.1 Stationarity & Heteroskedasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80567089",
   "metadata": {},
   "source": [
    "**Theory**\n",
    "\n",
    "A time series is a series of data points indexed in time. The fact that time series data are ordered makes them unique in the data space, as they often display serial dependency. Serial dependence occurs when the value of a data point at one point in time is statistically dependent on another data point at another point in time. However, this attribute of time series data violates one of the fundamental assumptions of many statistical analyses - that the data are statistically independent (Independent & Identically Distributed, IID, see https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) !\n",
    "\n",
    "Thus, we often need to assess some less restricting properties in order to deal (and model) time series. A time series is said to be *stationary* when its properties (such as the mean, the variance, the autocorrelation, etc...) do not change over time. This is a very useful property because it is the assumption underlying many predictive models in time series forecasting. Trends can result in a varying mean over time, whereas seasonality can result in a changing variance over time, and both will result in a non-stationary time serie. Specifically, *heteroskedasticity* refers to the property of having a non-constant variance. Thus, if a time serie is heteroskedastic, it is not stationary!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1ca76b",
   "metadata": {},
   "source": [
    "**Resources**\n",
    "- https://towardsdatascience.com/stationarity-in-time-series-analysis-90c94f27322\n",
    "- https://www.analyticsvidhya.com/blog/2021/06/statistical-tests-to-check-stationarity-in-time-series-part-1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c082d0a3",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "- Plot the time serie along with is rolling mean and variance.\n",
    "- Is this time serie stationary or not? Why ?\n",
    "- What about heteroskedasticity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2454cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot1: Combined Plot to assess\n",
    "# - \"Passengers\"\n",
    "# - \"Rolling mean\"\n",
    "# - \"Rolling standard deviation\"\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(3, 1, sharex=True, figsize=(12, 8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94e890c",
   "metadata": {},
   "source": [
    "### 3.2 Differencing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ab1d3",
   "metadata": {},
   "source": [
    "If the time series at hand is not stationary, we can apply some transformations to make it stationary. The difference transform helps stabilizing the mean of the time series by removing changes in the level of a time series, and so eliminating (or reducing) trend and seasonality. For a time series $Y_t$, its (first-order) difference $D_t$ is defined as\n",
    "$$D_t = Y_t - Y_{t-1}$$\n",
    "If you apply this difference transform iteratively, you can achieve what is called $n^{th}$-order differentiation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291ac974",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "- Write a function to compute the first-order difference of the time series and plot it.\n",
    "- Check your results by comparing to Pandas `.diff()` method.\n",
    "- What can you say about the trend and the seasonality ?\n",
    "- What about heteroskedasticity ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cdc616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(data):\n",
    "    # Compute the difference series\n",
    "    return diff\n",
    "    \n",
    "# Compute difference and plot\n",
    "\n",
    "\n",
    "# Compare with Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f103f622",
   "metadata": {},
   "source": [
    "Differencing can also be used to remove seasonality. In the above equations, we defined $D_t$ as the difference between two *consecutive*  values of the time series. But we can also take the difference on a larger interval of time, called the lag, $l$:\n",
    "$$ D_t = Y_t - Y_{t-l}$$\n",
    "where $l$ can be any integer $>1$. If we set $l$ to match the cyclic pattern of our time series, then we expect the difference transform to eliminate the seasonality. Let's try this out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(data, lag=1):\n",
    "    # Compute the difference series with lag\n",
    "    return diff\n",
    "\n",
    "lag = 12\n",
    "\n",
    "# Compute lagged difference and plot\n",
    "\n",
    "\n",
    "\n",
    "# Compare with Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f471dfde",
   "metadata": {},
   "source": [
    "### 3.3 Log-transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184f91bc",
   "metadata": {},
   "source": [
    "We will see that ARIMA models can take into account an increasing mean over time, but not the variance. In this case, we specifically want to get rid of the heteroskedasticity. To this aim, a very common operation is to apply a log transform.\n",
    "\n",
    "The log transform is very simple, it's just $\\tilde{Y}_t = \\log Y_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b91b5c9",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "- Compute the log transform of the time series and plot it.\n",
    "- Is it stationary ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a684c7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log transform and show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c4d861",
   "metadata": {},
   "source": [
    "### 3.4 Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61313fef",
   "metadata": {},
   "source": [
    "You now know how to detrend a dataset and how to tame heteroskedasticity. Let's see if we can use and combine these tools to make our time series stationary. To check if the transformed serie is indeed stationary, you can use two different stationarity tests: the *Augmented Dickey Fuller (ADF)* test and the *Kwiatkowski-Phillips-Schmidt-Shin (KPSS)* test.\n",
    "Note that the Null Hypothesis of the ADF test is that the serie is non-stationary, whereas the Null Hypothesis of the KPSS test is that the serie is stationary!\n",
    "\n",
    "\n",
    "**TODO**\n",
    "- Apply the log transform and differentiate the time series. Does the order matter ? Why ?\n",
    "- Plot the transformed time serie along with is rolling mean and variance. What do you observe ?\n",
    "- Perform the ADF and KPSS tests before and after your transformation. Is the transformed time serie stationary ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a07f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "\n",
    "def adf_test(timeseries):\n",
    "    print(\"Results of Dickey-Fuller Test:\")\n",
    "    dftest = adfuller(timeseries, autolag=\"AIC\")\n",
    "    dfoutput = pd.Series(\n",
    "        dftest[0:4],\n",
    "        index=[\n",
    "            \"Test Statistic\",\n",
    "            \"p-value\",\n",
    "            \"#Lags Used\",\n",
    "            \"Number of Observations Used\",\n",
    "        ],\n",
    "    )\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput[\"Critical Value (%s)\" % key] = value\n",
    "    print(dfoutput)\n",
    "\n",
    "def kpss_test(timeseries):\n",
    "    print(\"Results of KPSS Test:\")\n",
    "    kpsstest = kpss(timeseries, regression=\"c\", nlags=\"auto\")\n",
    "    kpss_output = pd.Series(\n",
    "        kpsstest[0:3], index=[\"Test Statistic\", \"p-value\", \"Lags Used\"]\n",
    "    )\n",
    "    for key, value in kpsstest[3].items():\n",
    "        kpss_output[\"Critical Value (%s)\" % key] = value\n",
    "    print(kpss_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff528df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f773de",
   "metadata": {},
   "source": [
    "# 4. Auto-correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55797cd9",
   "metadata": {},
   "source": [
    "**Theory**\n",
    "\n",
    "We said earlier that time series are particular because they show a serial (temporal) dependence, namely observations at a certain time $t$ are statistically correlated to previous observations. It will be useful to our analysis to measure quantitatively this serial dependence with the help of the mathematical tools of *Covariance*, *Correlation* and the related *Auto-Correlation*.\n",
    "\n",
    "Let's first recall some definitions.\n",
    "- The sample mean of $X$ is $\\mu_X = \\frac{1}{N} \\sum_{i=1}^N X_i$ is a measure of the expected average value.\n",
    "- The variance of $X$ is $V_X = \\frac{1}{N} \\sum_{i=1}^N (X_i - \\mu_X)^2$, it is a measure of the squared deviation around the mean.\n",
    "- The standard deviation of $X$ is $\\sigma_X = \\sqrt{V_X}$, it is a measure of the Root-Mean-Square deviation around the mean.\n",
    "- The covariance of two series $X$ and $Y$ is $V(X,Y) = \\frac{1}{N} \\sum_{i=1}^N (X_i - \\mu_X)(Y_i - \\mu_Y)$, it is a measure of the joint variability of the two series.\n",
    "- The correlation of two series $X$ and $Y$ is $C(X,Y) = V(X,Y) / \\sigma_X \\sigma_Y$, it is a measure of the statistical correlation (\"Normalized Covariance\") of the two series.\n",
    "\n",
    "Finally, the Auto-Correlation Function (ACF) $ A_X(h) = C(Y_t, Y_{t-h}) $ measures for each lag $h = 1, 2, 3, ...$ the average correlation of a time series with a lagged version of itself. It measures the correlation of an observation $Y_t$ with the one $h$ time stamps before $Y_{t-h}$, on average over all the observations!\n",
    "\n",
    "One more thing: while the ACF measures the **full** correlation between $Y$ and $Y_{t-h}$, the **Partial** Auto-Correlation Function (PACF) measures only the **direct** correlation between $Y$ and $Y_{t-h}$, by removing the contribution from the intermediate correlations. Its calculation is not unique and sometimes relies on models, so we will not say how it's calculated here.\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c029908a",
   "metadata": {},
   "source": [
    "**Resources**\n",
    "- https://towardsdatascience.com/understanding-autocorrelation-in-time-series-analysis-322ad52f2199\n",
    "- https://emel333.medium.com/interpreting-autocorrelation-partial-autocorrelation-plots-for-time-series-analysis-23f87b102c64\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7ad2c",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "- Plot the ACF and PACF of the original &  transformed dataset (log + diff)\n",
    "- Can you interpret the differences ?\n",
    "- Can you find the periodicity by looking at the ACF/PACF on the transformed dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cd4e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Plot the ACF and PACF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e36919e",
   "metadata": {},
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dfa154",
   "metadata": {},
   "source": [
    "## Bonus #1 Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b488149c",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "- Think of a *very basic* way to predict the number of passengers on the next month ? Show your results. What's the source of the error ?\n",
    "- Extend your method to predict a whole year ? Show your results. Again, what's the error ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6591ce",
   "metadata": {},
   "source": [
    "## Bonus #2 Automatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed75de1",
   "metadata": {},
   "source": [
    "**TODO - Write a class with the following methods:**\n",
    "* A `check format` method to check format and eventually change it to datetime format\n",
    "* A `visualize` method with <span style=\"color:red\"> Plotly</span>\n",
    "* A `seasonal_decompose` method setting the relevant attributes (trend, seasonality, residual)\n",
    "* A `plot_acf` and `plot_pacf` method\n",
    "* A `transform` method (differencing, log)\n",
    "* A `report` method to provide a report about observations on your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a4f8a9",
   "metadata": {},
   "source": [
    "## Bonus #3 Fast Fourier Transform (FFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8260c32e",
   "metadata": {},
   "source": [
    "**Resources**\n",
    "\n",
    "- https://ipython-books.github.io/101-analyzing-the-frequency-components-of-a-signal-with-a-fast-fourier-transform/\n",
    "\n",
    "**TODO**\n",
    "\n",
    "- The Fourier Transform is related to the ACF... How ?\n",
    "- Analyse the frequency spectrum of the dataset. What is the meaning of the different frequency peaks ?\n",
    "- Plot the signal obtained by keeping only the most prominent frequencies. Is this enough to describe all the variations in the signal ?\n",
    "- What is the meaning of high frequencies ? What would be a meaningful frequency cutoff ?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML6bis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
